{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../Lib/')\n",
    "import numpy as np\n",
    "import pickle, os, lib, rep_lib, json, datetime\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataset for Repetita\n",
    "\n",
    "### Make sure to point the path to the folder containing the Repetita files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_repetita = \"../Dataset/Repetita\"\n",
    "path_TM= \"../TM\"\n",
    "path_results = \"../Results\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(topology):\n",
    "    for scale in [0.1, 0.5, 0.75, 1]:\n",
    "        for number in range(5):\n",
    "            traffic = rep_lib.load_traffic(f\"{path_repetita}/data/{topology}.000{number}.demands\")\n",
    "\n",
    "\n",
    "            t = np.empty((len(traffic), 1),dtype=tuple)\n",
    "            for i, element in enumerate(traffic):\n",
    "                traffic[i] = (element[0], element[1]*scale)\n",
    "                t[i,0] = traffic[i]\n",
    "\n",
    "            G = rep_lib.load_topo(f\"{path_repetita}/data/{topology}.graph\", traffic)\n",
    "            if not os.path.exists(f\"{path_TM}/Repetita/{topology}/\"):\n",
    "                os.makedirs(f\"{path_TM}/Repetita/{topology}/\")\n",
    "            file = open(f\"{path_TM}/Repetita/{topology}/000{number}_{scale}.pkl\", 'wb')\n",
    "            pickle.dump((G, t), file)\n",
    "    print(len(G.edges)/2)\n",
    "    print(len(G.edges)/ (2* len(G.nodes)))\n",
    "    util, total_bw = rep_lib.get_utilization(G)\n",
    "    print(util/total_bw)\n",
    "\n",
    "path = f\"{path_repetita}/data/2016TopologyZooUCL_inverseCapacity/\"\n",
    "for name in os.listdir(path):\n",
    "    folder = path.split(\"/\")[-2]\n",
    "    if name.endswith(\".graph\"):\n",
    "        print(name)\n",
    "        topo_name = name.split(\".\")[0]\n",
    "        print(f\"{folder}/{topo_name}\")\n",
    "        create_dataset(f\"{folder}/{topo_name}\")\n",
    "\n",
    "path = f\"{path_repetita}/data/2016RocketFuelUCL/\"\n",
    "for name in os.listdir(path):\n",
    "    folder = path.split(\"/\")[-2]\n",
    "    if name.endswith(\".graph\"):\n",
    "        print(name)\n",
    "        topo_name = name.split(\".\")[0]\n",
    "        print(f\"{folder}/{topo_name}\")\n",
    "        create_dataset(f\"{folder}/{topo_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(topo):\n",
    "    result = []\n",
    "    scales = [0.1,0.5,0.75,1]\n",
    "    timesteps = [0,1,2,3,4]\n",
    "\n",
    "    for scale in scales:\n",
    "\n",
    "        for i in timesteps:\n",
    "            \n",
    "            ts = i\n",
    "            links_off = []\n",
    "            file = open(f\"{path_TM}/Repetita/{topo}/000{ts}_{scale}.pkl\", \"rb\")\n",
    "            G, t = pickle.load(file)\n",
    "            budget = lib.get_reroute_budget(G)\n",
    "            result.append(dict(config={\"scale\":scale,\"timestep\":ts,\"reroute_budget\": budget, \"topo\": topo}))\n",
    "            topo_graph = nx.MultiGraph()\n",
    "            topo_graph.add_nodes_from(G.nodes())\n",
    "            sleep_edges = []\n",
    "\n",
    "            for edge in G.edges:\n",
    "                if topo_graph.has_edge(edge[1],edge[0],tuple(reversed(edge[2]))):\n",
    "                    continue\n",
    "                else:\n",
    "                    topo_graph.add_edge(edge[0], edge[1], key=edge[2], sleep=False, max_bw=G[edge[0]][edge[1]][edge[2]][\"max_bw\"])\n",
    "                    sleep_edges.append(edge)\n",
    "\n",
    "            edges_to_sleep = lib.get_links_to_sleep(sleep_edges, G, link_margin=0.2)\n",
    "            edges_to_sleep = lib.optimize_link_sleep(edges_to_sleep, G)\n",
    "            \n",
    "            for sleep_edge, score in edges_to_sleep:\n",
    "                if budget - score < 0:\n",
    "                    break\n",
    "                if lib.check_connectedness(sleep_edge, topo_graph) == False:\n",
    "                    continue\n",
    "\n",
    "                budget -= score\n",
    "                topo_graph[sleep_edge[0]][sleep_edge[1]][sleep_edge[2]][\"sleep\"] = True\n",
    "                links_off.append(sleep_edge)\n",
    "            result[-1][\"sleep_edges\"] = links_off\n",
    "            result[-1][\"ol_now\"] = lib.check_overload(f\"{path_TM}/Repetita/{topo}/000{ts}_{scale}.pkl\", topo_graph)\n",
    "\n",
    "    for element in result:\n",
    "        ol_now = (len(element[\"ol_now\"][\"ol_sleep\"])-len(element[\"ol_now\"][\"ol_active\"]), len(element[\"ol_now\"][\"ol_sleep_1\"])-len(element[\"ol_now\"][\"ol_active_1\"]))\n",
    "        element[\"result\"] = {\"scale\": element[\"config\"][\"scale\"] ,\"ol_now\":ol_now, \"no_sleep\": len(element[\"sleep_edges\"])}\n",
    "        print(element[\"result\"])\n",
    "\n",
    "    if not os.path.exists(f\"{path_results}/repetita/\"):\n",
    "            os.makedirs(f\"{path_results}/repetita/\")\n",
    "    lib.save_result(f\"{path_results}/repetita/\", result)\n",
    "    return\n",
    "\n",
    "path = f\"{path_TM}/Repetita/2016TopologyZooUCL_inverseCapacity/\"\n",
    "for name in os.listdir(path):\n",
    "    folder = path.split(\"/\")[-2]\n",
    "    topo = f\"{folder}/{name}\"\n",
    "    print(topo)\n",
    "    eval(topo)\n",
    "\n",
    "path = f\"{path_TM}/Repetita/2016RocketFuelUCL/\"\n",
    "for name in os.listdir(path):\n",
    "    folder = path.split(\"/\")[-2]\n",
    "    topo = f\"{folder}/{name}\"\n",
    "    print(topo)\n",
    "    eval(topo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show results of Repetita experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_repetita(path, show=False):\n",
    "    dataset = {}\n",
    "\n",
    "    for i in [0.1,0.5,0.75,1]:\n",
    "        with open(f\"{path}/scale_{i}.txt\", \"r\") as f:\n",
    "            dataset[f\"scale_{i}\"] = []\n",
    "            lines = f.readlines()\n",
    "            for line in lines:\n",
    "                line = line.split(\",\")\n",
    "                dataset[f\"scale_{i}\"].append((line[0], json.loads(','.join(line[1:]))))\n",
    "\n",
    "    for key in dataset.keys():\n",
    "\n",
    "        result_dict = {\"no_sleep\": [], \"ol\": [], \"ol_1\": [], \"ts\": [], \"best_case\": [], \"no_of_links\": [], \"no_of_nodes\": [], \"avg_degree\":[],\"avg_util\":[], \"diameter\":[], \"actual_sleep\": []}\n",
    "        for i, element in enumerate(dataset[key]):\n",
    "            topo = element[1][\"config\"][\"topo\"]\n",
    "            ts = element[1][\"config\"][\"timestep\"]\n",
    "            scale = element[1][\"config\"][\"scale\"]\n",
    "            file = open(f\"{path_TM}/Repetita/{topo}/000{ts}_{scale}.pkl\", \"rb\")\n",
    "            G, t = pickle.load(file)\n",
    "            result_dict[\"best_case\"].append(len(G.edges)/2 - len(G.nodes) + 1)\n",
    "            result_dict[\"no_of_nodes\"].append(len(G.nodes))\n",
    "            result_dict[\"no_of_links\"].append(len(G.edges)/2)\n",
    "            utilizations = []\n",
    "\n",
    "            for edge in G.edges:\n",
    "                utilizations.append((G[edge[0]][edge[1]][edge[2]][\"usage\"],G[edge[0]][edge[1]][edge[2]][\"max_bw\"]))\n",
    "\n",
    "            utilizations = np.array(utilizations)\n",
    "            abs_util = np.sum(utilizations[:,0])\n",
    "            util = np.sum(utilizations[:,0])/np.sum(utilizations[:,1])\n",
    "            result_dict[\"avg_util\"].append(util)\n",
    "            H = nx.MultiGraph(G)\n",
    "            result_dict[\"avg_degree\"].append(np.mean([x[1] for x in H.degree]))\n",
    "            result_dict[\"diameter\"].append(nx.diameter(G))\n",
    "            ol_now = element[1][\"result\"][\"ol_now\"]\n",
    "            result_dict[\"ts\"].append(datetime.datetime.fromtimestamp((element[1][\"config\"][\"timestep\"])))\n",
    "            result_dict[\"no_sleep\"].append(element[1][\"result\"][\"no_sleep\"])\n",
    "            result_dict[\"ol\"].append(ol_now[0])\n",
    "            result_dict[\"ol_1\"].append(ol_now[1])\n",
    "            if ol_now == [0,0]:\n",
    "                result_dict[\"actual_sleep\"].append(element[1][\"result\"][\"no_sleep\"])\n",
    "            else:\n",
    "                result_dict[\"actual_sleep\"].append(0)\n",
    "\n",
    "        if show:\n",
    "            print(key)\n",
    "            print(f'best_case: {np.mean(result_dict[\"best_case\"])}, no_of_links: {np.mean(result_dict[\"no_of_links\"])}, no_of_nodes: {np.mean(result_dict[\"no_of_nodes\"])}')\n",
    "            print(f'avg_degree: {np.mean(result_dict[\"avg_degree\"])}, avg_util: {np.mean(result_dict[\"avg_util\"])} , diameter: {np.mean(result_dict[\"diameter\"])}')\n",
    "            print(f'no of timesteps: {len(result_dict[\"no_sleep\"])}')\n",
    "            print(f'links turned off: {np.mean(result_dict[\"no_sleep\"])}, actual after correction: {np.mean(result_dict[\"actual_sleep\"])}')\n",
    "            print(f'Avg. link over 80%: {np.mean(result_dict[\"ol\"])}, no. of times it happens: {np.count_nonzero(result_dict[\"ol\"])}')\n",
    "            print(f'Avg. link over 100%: {np.mean(result_dict[\"ol_1\"])}, no. of times it happens: {np.count_nonzero(result_dict[\"ol_1\"])}')\n",
    "\n",
    "            print()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = f\"{path_results}/repetita/\"\n",
    "show_repetita(path, show=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
